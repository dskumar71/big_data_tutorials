{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import org.apache.spark.ml.feature.Imputer\n",
    "\n",
    "val imputer = new Imputer()\n",
    "  .setInputCols(df.columns)\n",
    "  .setOutputCols(df.columns.map(c => s\"${c}_imputed\"))\n",
    "  .setStrategy(\"mean\")\n",
    "\n",
    "imputer.fit(df).transform(df)\n",
    "\n",
    "\n",
    "\n",
    " df.na.fill(10.0,Seq(\"age\"))\n",
    "// res4: org.apache.spark.sql.DataFra\n",
    "\n",
    "\n",
    "\n",
    "import org.apache.spark.{ SparkConf, SparkContext }\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "import org.apache.log4j.{ Logger, Level }\n",
    "\n",
    "object MissingImputation {\n",
    "\n",
    "  def main(args: Array[String]) {\n",
    "    var logger = Logger.getLogger(this.getClass())\n",
    "\n",
    "    val conf = new SparkConf().setAppName(\"Missing Data Imputation\").setMaster(\"local[*]\")\n",
    "    val sc = new SparkContext(conf)\n",
    "    val sqlContext = new SQLContext(sc)\n",
    "    val rootLogger = Logger.getRootLogger()\n",
    "    rootLogger.setLevel(Level.ERROR)\n",
    "\n",
    "    import sqlContext.implicits._\n",
    "    val df = sqlContext.read\n",
    "      .format(\"com.databricks.spark.csv\")\n",
    "      .option(\"header\", \"true\")\n",
    "      .option(\"inferSchema\", \"true\")\n",
    "      .load(\"resources/sample.csv\")\n",
    "\n",
    "    val dataTypeList = df.dtypes.toList\n",
    "    println(dataTypeList)\n",
    "\n",
    "    //utility\n",
    "    dataTypeList.foreach(x => if (x._2.startsWith(\"Str\")) println(x._1))\n",
    "\n",
    "    //finding all string column and frequentWord\n",
    "    val stringColumnList = dataTypeList.filter(x => x._2.startsWith(\"Str\"))\n",
    "    val frequencyList = stringColumnList.map(x => df.groupBy(x._1).count().sort(desc(\"count\")).take(5).filter(x => !(\"\".equals(x(0)) || \"N.A.\".equals(x(0)) || \"N.A.//\".equals(x(0))))(0).get(0).asInstanceOf[String])\n",
    "    val result = frequencyList.map(_.toString)\n",
    "\n",
    "    //finding int column and calculating avg \n",
    "    val numberColumnList = dataTypeList.filter(x => x._2.startsWith(\"Integer\") || x._2.startsWith(\"Long\"))\n",
    "    val numbersAVG = numberColumnList.map(x => df.select(avg(x._1)).first)\n",
    "    numberColumnList.foreach(println(_))\n",
    " df.groupBy($\"department\").avg().foreach(println(_))\n",
    "   \n",
    "    val nullifiedDF = df.withColumn(\"uname\", blankAsNull(\"uname\"))\n",
    "\n",
    "    val replaced = nullifiedDF.na.fill(result(0), Seq(\"uname\"))\n",
    "    replaced.printSchema()\n",
    "    replaced.take(20).foreach { x => println(x.toString()) }\n",
    "    \n",
    "    \n",
    "//    val x=if(stringColumnList.contains(x)) blankAsNull(x._1).alias(x._1) else for(x <- df.columns) x)\n",
    "    \n",
    "    val test= df.dtypes.map(x=> if(stringColumnList.contains(x)) blankAsNull(x._1).alias(x._1) else for(x <- df.columns) x)\n",
    "     test.take(20).foreach { x => println(x.toString()) }\n",
    "  }\n",
    "  \n",
    "  \n",
    "  def blankAsNull(x: String): Column = {\n",
    "    return when(col(x) === \"N.A//\" || col(x) === \"N.A.\" || col(x) === \"NA\"|| col(x) === \"\", null)\n",
    "      .otherwise(col(x))\n",
    "  }\n",
    "\n",
    "  def createMap(res: String): Map[String, String] = {\n",
    "    val userList = List(\"N.A.\", \"N.A.//\", \"\", \" \")\n",
    "    val resultList = userList.map { x => res }\n",
    "    return userList.zip(resultList).toMap\n",
    "\n",
    "  }\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
